{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "- Setup \n",
    "    - Dataset and DataLoader\n",
    "    - Training loop\n",
    "    - Model architecture\n",
    "- Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor, Tensor\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from utils import display_tensor_as_image, transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device.type = 'cpu'\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f'{device.type = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "mnist_loader = DataLoader(dataset=mnist, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=112x112>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_tensor_as_image(mnist[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def train_one_epoch(model: nn.Module, dataloader: DataLoader, loss_fn: Callable[[Tensor, Tensor], Tensor], optimizer: torch.optim.Optimizer) -> float:\n",
    "    epoch_running_loss = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        inputs, labels = batch\n",
    "\n",
    "        inputs = inputs.to(device) #  move to GPU if available\n",
    "        labels = labels.to(device) #  move to GPU if available\n",
    "\n",
    "        optimizer.zero_grad() # zero gradients\n",
    "\n",
    "        predictions = model(inputs)\n",
    "\n",
    "        # compute loss and propogate gradients\n",
    "        loss = loss_fn(predictions, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # update metainformation\n",
    "        epoch_running_loss += loss.item()\n",
    "\n",
    "    epoch_avg_loss = epoch_running_loss / len(dataloader)\n",
    "    return epoch_avg_loss\n",
    "\n",
    "\n",
    "def train_n_epochs(n: int, model: nn.Module, dataloader: DataLoader, loss_fn: Callable[[Tensor, Tensor], Tensor], optimizer: torch.optim.Optimizer) -> None:\n",
    "    for i in range(n):\n",
    "        epoch_avg_loss = train_one_epoch(model, dataloader, loss_fn, optimizer)\n",
    "        print(f'epoch {i}: {epoch_avg_loss = }')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    '''\n",
    "    Convolutional Neural Network\n",
    "    '''\n",
    "    def __init__(self, n_kernels, kernel_size):\n",
    "        super(CNN, self).__init__()\n",
    "        in_channels = 1 # grayscale image\n",
    "        padding = int((kernel_size - 1) / 2) # this is the formula to preserve size assuming a stride of 1\n",
    "\n",
    "        self.conv_1 = nn.Conv2d(in_channels=in_channels,\n",
    "                                out_channels=n_kernels,\n",
    "                                kernel_size=kernel_size,\n",
    "                                stride=1,\n",
    "                                padding=padding)\n",
    "        self.pooling_1 = nn.MaxPool2d(kernel_size=2, stride=2) # this downsamples the input by factor of 2\n",
    "\n",
    "        # n_weights_per_kernel = (kernel_size * kernel_size * in_channels) // 2 # after the downsampling\n",
    "        # in_features = n_weights_per_kernel * n_kernels\n",
    "\n",
    "        in_features = int(28 / 2) ** 2 # 28*28 gets downsampled to 14*14\n",
    "        self.fully_connected_1 = nn.Linear(in_features, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f'{x.shape = }')\n",
    "        x = self.conv_1(x)\n",
    "        print(f'conv_1(x) =>             {x.shape = }')\n",
    "        x = self.pooling_1(x)\n",
    "        print(f'pooling_1(x) =>          {x.shape = }')\n",
    "        x = x.flatten()\n",
    "        print(f'x.flatten() =>           {x.shape = }')\n",
    "        x = self.fully_connected_1(x)\n",
    "        print(f'x.fully_connected_1() => {x.shape = }')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = torch.Size([1, 28, 28])\n",
      "conv_1(x) =>             x.shape = torch.Size([1, 28, 28])\n",
      "pooling_1(x) =>          x.shape = torch.Size([1, 14, 14])\n",
      "x.flatten() =>           x.shape = torch.Size([196])\n",
      "x.fully_connected_1() => x.shape = torch.Size([10])\n",
      "torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0750,  0.2866,  0.1940,  0.0928, -0.1657,  0.1932,  0.0901, -0.6652,\n",
       "         0.0971,  0.1767], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = torch.ones(1, 28, 28)\n",
    "\n",
    "# m = CNN(1, 3)\n",
    "\n",
    "# out = m(x)\n",
    "# print(out.shape)\n",
    "# out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
