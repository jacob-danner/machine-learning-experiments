{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install duckdb -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "import torch.nn as nn\n",
    "import duckdb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device.type = 'cpu'\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f'{device.type = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌──────────────────┐\n",
       "│       name       │\n",
       "│     varchar      │\n",
       "├──────────────────┤\n",
       "│ choon_images     │\n",
       "│ not_choon_images │\n",
       "└──────────────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = duckdb.connect('choon_dataset.db')\n",
    "\n",
    "con.sql('SHOW TABLES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_tensors</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.7764706, 0.78039217, 0.78039217, 0.78039217...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.7764706, 0.78039217, 0.76862746, 0.7647059,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.73333335, 0.74509805, 0.7529412, 0.7372549,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.83137256, 0.8392157, 0.84313726, 0.8352941,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.85490197, 0.8509804, 0.8509804, 0.8509804, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       image_tensors  label\n",
       "0  [0.7764706, 0.78039217, 0.78039217, 0.78039217...      1\n",
       "1  [0.7764706, 0.78039217, 0.76862746, 0.7647059,...      1\n",
       "2  [0.73333335, 0.74509805, 0.7529412, 0.7372549,...      1\n",
       "3  [0.83137256, 0.8392157, 0.84313726, 0.8352941,...      1\n",
       "4  [0.85490197, 0.8509804, 0.8509804, 0.8509804, ...      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choon_df = (\n",
    "    con.sql('FROM choon_images').df()\n",
    "    .assign(label=1)\n",
    ")\n",
    "not_choon_df = (\n",
    "    con.sql('FROM not_choon_images').df()\n",
    "    .assign(label=0)\n",
    ")\n",
    "\n",
    "all_df = (\n",
    "    pd.concat([choon_df, not_choon_df])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "con.close()\n",
    "\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "\tlen =   272\n",
      "\t% 0's = 0.54\n",
      "\t% 1's = 0.46\n",
      "validate\n",
      "\tlen =   59\n",
      "\t% 0's = 0.47\n",
      "\t% 1's = 0.53\n",
      "test\n",
      "\tlen =   58\n",
      "\t% 0's = 0.57\n",
      "\t% 1's = 0.43\n"
     ]
    }
   ],
   "source": [
    "all_shuffled = all_df.sample(frac=1, random_state=3).reset_index(drop=True)\n",
    "\n",
    "train_frac = 0.7  # 70% for training\n",
    "test_frac = 0.15  # 15% for testing\n",
    "validate_frac = 0.15  # 15% for validation\n",
    "\n",
    "total_len = len(all_shuffled)\n",
    "train_len = int(total_len * train_frac)\n",
    "test_len = int(total_len * test_frac)\n",
    "validate_len = total_len - train_len - test_len\n",
    "\n",
    "train_df = all_shuffled[:train_len]\n",
    "test_df = all_shuffled[train_len:train_len+test_len]\n",
    "validate_df = all_shuffled[train_len+test_len:]\n",
    "\n",
    "dfs = {\n",
    "    'train': train_df,\n",
    "    'validate': validate_df,\n",
    "    'test': test_df\n",
    "}\n",
    "\n",
    "for name, df in dfs.items():\n",
    "    percentages = df.label.value_counts() / len(df)\n",
    "    percentages = round(percentages, 2)\n",
    "    percent_0, percent_1 = percentages[0], percentages[1]\n",
    "    print(f\"{name}\")\n",
    "    print(f'\\tlen =   {len(df)}')\n",
    "    print(f\"\\t% 0's = {percent_0}\\n\\t% 1's = {percent_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class ChoonDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = tensor(row['image_tensors']).view(3, 256, 256)\n",
    "        label = tensor(float(row['label']))\n",
    "        return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train) = 272, len(validate) = 59, len(test) = 58\n",
      "\n",
      "(tensor([[[0.7255, 0.7137, 0.7098,  ..., 0.7137, 0.7961, 0.8118],\n",
      "         [0.7216, 0.7059, 0.6941,  ..., 0.6902, 0.7647, 0.7176],\n",
      "         [0.7176, 0.7020, 0.6863,  ..., 0.6118, 0.6980, 0.6745],\n",
      "         ...,\n",
      "         [0.1451, 0.3333, 0.4588,  ..., 0.0784, 0.0588, 0.0706],\n",
      "         [0.1373, 0.3333, 0.3765,  ..., 0.0902, 0.0863, 0.0706],\n",
      "         [0.1137, 0.3451, 0.3569,  ..., 0.0510, 0.0784, 0.0980]],\n",
      "\n",
      "        [[0.7922, 0.7843, 0.7843,  ..., 0.7412, 0.8549, 0.8627],\n",
      "         [0.7882, 0.7765, 0.7686,  ..., 0.7137, 0.8196, 0.7765],\n",
      "         [0.7882, 0.7765, 0.7608,  ..., 0.6314, 0.7412, 0.7294],\n",
      "         ...,\n",
      "         [0.1412, 0.3255, 0.4392,  ..., 0.1137, 0.0941, 0.0941],\n",
      "         [0.1373, 0.3216, 0.3647,  ..., 0.1216, 0.1216, 0.0941],\n",
      "         [0.1137, 0.3373, 0.3451,  ..., 0.0863, 0.1137, 0.1216]],\n",
      "\n",
      "        [[0.8627, 0.8510, 0.8510,  ..., 0.7137, 0.8235, 0.8275],\n",
      "         [0.8588, 0.8431, 0.8353,  ..., 0.6941, 0.7922, 0.7490],\n",
      "         [0.8549, 0.8431, 0.8275,  ..., 0.6235, 0.7137, 0.7020],\n",
      "         ...,\n",
      "         [0.1176, 0.2667, 0.3765,  ..., 0.1098, 0.0902, 0.1020],\n",
      "         [0.1137, 0.2667, 0.3020,  ..., 0.1216, 0.1176, 0.0980],\n",
      "         [0.0824, 0.2784, 0.2863,  ..., 0.0902, 0.1098, 0.1216]]]), tensor(0.))\n",
      "(tensor([[[0.1373, 0.1608, 0.2039,  ..., 0.6078, 0.5804, 0.5647],\n",
      "         [0.1255, 0.1373, 0.1412,  ..., 0.6118, 0.5804, 0.5608],\n",
      "         [0.1176, 0.1176, 0.1176,  ..., 0.6275, 0.5882, 0.5608],\n",
      "         ...,\n",
      "         [0.7922, 0.7647, 0.7765,  ..., 0.7294, 0.9137, 0.9255],\n",
      "         [0.7804, 0.7804, 0.7843,  ..., 0.8314, 0.7412, 0.9373],\n",
      "         [0.7843, 0.8000, 0.8039,  ..., 0.9412, 0.7804, 0.7804]],\n",
      "\n",
      "        [[0.1176, 0.1333, 0.1686,  ..., 0.5529, 0.5216, 0.5059],\n",
      "         [0.0902, 0.0980, 0.1059,  ..., 0.5569, 0.5216, 0.5020],\n",
      "         [0.0784, 0.0784, 0.0824,  ..., 0.5725, 0.5294, 0.5020],\n",
      "         ...,\n",
      "         [0.5333, 0.5059, 0.5176,  ..., 0.7451, 0.9373, 0.9529],\n",
      "         [0.5216, 0.5216, 0.5255,  ..., 0.8588, 0.7647, 0.9569],\n",
      "         [0.5255, 0.5412, 0.5451,  ..., 0.9647, 0.8039, 0.8000]],\n",
      "\n",
      "        [[0.0980, 0.1098, 0.1451,  ..., 0.4706, 0.4392, 0.4235],\n",
      "         [0.0824, 0.0902, 0.0980,  ..., 0.4745, 0.4392, 0.4196],\n",
      "         [0.0706, 0.0745, 0.0784,  ..., 0.4902, 0.4471, 0.4196],\n",
      "         ...,\n",
      "         [0.3373, 0.3098, 0.3216,  ..., 0.7961, 0.9490, 0.9608],\n",
      "         [0.3255, 0.3255, 0.3294,  ..., 0.8824, 0.8157, 0.9608],\n",
      "         [0.3294, 0.3451, 0.3490,  ..., 0.9686, 0.8471, 0.8392]]]), tensor(0.))\n",
      "(tensor([[[0.6314, 0.6353, 0.6353,  ..., 0.2627, 0.2745, 0.2784],\n",
      "         [0.6353, 0.6314, 0.6314,  ..., 0.2627, 0.2549, 0.2588],\n",
      "         [0.6353, 0.6353, 0.6314,  ..., 0.2510, 0.2275, 0.2235],\n",
      "         ...,\n",
      "         [0.3843, 0.3922, 0.4000,  ..., 0.5608, 0.5608, 0.5608],\n",
      "         [0.3725, 0.3843, 0.3922,  ..., 0.5647, 0.5608, 0.5569],\n",
      "         [0.4824, 0.4118, 0.3843,  ..., 0.5608, 0.5608, 0.5608]],\n",
      "\n",
      "        [[0.6275, 0.6314, 0.6314,  ..., 0.4078, 0.4196, 0.4235],\n",
      "         [0.6314, 0.6275, 0.6275,  ..., 0.4078, 0.4000, 0.4000],\n",
      "         [0.6314, 0.6314, 0.6275,  ..., 0.3882, 0.3608, 0.3608],\n",
      "         ...,\n",
      "         [0.3686, 0.3765, 0.3843,  ..., 0.5529, 0.5529, 0.5529],\n",
      "         [0.3569, 0.3647, 0.3765,  ..., 0.5569, 0.5529, 0.5490],\n",
      "         [0.4588, 0.3922, 0.3686,  ..., 0.5529, 0.5529, 0.5529]],\n",
      "\n",
      "        [[0.6118, 0.6157, 0.6157,  ..., 0.4392, 0.4510, 0.4549],\n",
      "         [0.6157, 0.6118, 0.6118,  ..., 0.4392, 0.4314, 0.4353],\n",
      "         [0.6157, 0.6157, 0.6118,  ..., 0.4235, 0.4000, 0.4000],\n",
      "         ...,\n",
      "         [0.3255, 0.3333, 0.3412,  ..., 0.5059, 0.5059, 0.5059],\n",
      "         [0.3098, 0.3294, 0.3451,  ..., 0.5098, 0.5059, 0.5020],\n",
      "         [0.3961, 0.3451, 0.3294,  ..., 0.5059, 0.5059, 0.5059]]]), tensor(1.))\n"
     ]
    }
   ],
   "source": [
    "train = ChoonDataset(train_df)\n",
    "validate = ChoonDataset(validate_df)\n",
    "test = ChoonDataset(test_df)\n",
    "\n",
    "print(f'{len(train) = }, {len(validate) = }, {len(test) = }\\n', sep='\\n')\n",
    "print(train[0], validate[0], test[0], sep='\\n')\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=16, shuffle=True)\n",
    "validate_loader = DataLoader(validate, batch_size=16)\n",
    "test_loader = DataLoader(test, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from dataclasses import dataclass\n",
    "from torch import Tensor\n",
    "\n",
    "def validate_one_epoch(model: nn.Module, validation_dataloader: DataLoader, loss_fn: Callable[[Tensor, Tensor], Tensor]) -> tuple[float, float]:\n",
    "    '''return the loss and the accuracy of the model on the validation dataloader'''\n",
    "    model.eval()\n",
    "\n",
    "    epoch_running_loss = 0\n",
    "    total_samples = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in validation_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model(inputs)\n",
    "\n",
    "            # calculate loss\n",
    "            loss = loss_fn(logits, labels)\n",
    "            epoch_running_loss += loss.item()\n",
    "\n",
    "            # caluclate accuracy\n",
    "            _, predictions = torch.max(logits, 1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total_samples += len(inputs)\n",
    "\n",
    "    epoch_avg_loss = epoch_running_loss / len(validation_dataloader)\n",
    "    accuracy = correct / total_samples\n",
    "    \n",
    "    return epoch_avg_loss, accuracy\n",
    "\n",
    "\n",
    "def train_one_epoch(model: nn.Module, dataloader: DataLoader, loss_fn: Callable[[Tensor, Tensor], Tensor], optimizer: torch.optim.Optimizer) -> float:\n",
    "    '''train the model for one epoch. return the average loss of the epoch'''\n",
    "    model.train()\n",
    "\n",
    "    epoch_running_loss = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        inputs, labels = batch\n",
    "\n",
    "        inputs = inputs.to(device) #  move to GPU if available\n",
    "        labels = labels.to(device) #  move to GPU if available\n",
    "\n",
    "        optimizer.zero_grad() # zero gradients\n",
    "\n",
    "        predictions = model(inputs)\n",
    "\n",
    "        # compute loss and propogate gradients\n",
    "        loss = loss_fn(predictions, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # update metainformation\n",
    "        epoch_running_loss += loss.item()\n",
    "\n",
    "    epoch_avg_loss = epoch_running_loss / len(dataloader)\n",
    "    return epoch_avg_loss\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainingRunInfo():\n",
    "    avg_training_losses: list[float]\n",
    "    avg_validation_losses: list[float]\n",
    "    validation_accuracies: list[float]\n",
    "\n",
    "def train_n_epochs(\n",
    "    n: int,\n",
    "    model: nn.Module,\n",
    "    train_dataloader: DataLoader,\n",
    "    validation_dataloader: DataLoader,\n",
    "    loss_fn: Callable[[Tensor, Tensor], Tensor],\n",
    "    optimizer: torch.optim.Optimizer\n",
    "    ) -> TrainingRunInfo:\n",
    "\n",
    "    avg_training_losses = []\n",
    "    avg_validation_losses = []\n",
    "    validation_accuracies = []\n",
    "\n",
    "    for i in range(n):\n",
    "        epoch_train_avg_loss = train_one_epoch(model, train_dataloader, loss_fn, optimizer)\n",
    "        epoch_validation_avg_loss, epoch_validation_accuracy = validate_one_epoch(model, validation_dataloader, loss_fn)\n",
    "\n",
    "        avg_training_losses.append(epoch_train_avg_loss)\n",
    "        avg_validation_losses.append(epoch_validation_avg_loss)\n",
    "        validation_accuracies.append(epoch_validation_accuracy)\n",
    "\n",
    "        print(f'EPOCH {i}:') \n",
    "        print(f'train - epoch avg loss: {epoch_train_avg_loss}')\n",
    "        print(f'valid - epoch avg loss: {epoch_validation_avg_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model = models.resnet50(weights='DEFAULT')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_in = model.fc.in_features\n",
    "custom_head = nn.Linear(pretrained_in, 1)\n",
    "model.fc = custom_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(lr=.001, params=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "training_run_info = train_n_epochs(1, model, train_loader, validate_loader, loss_fn, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
